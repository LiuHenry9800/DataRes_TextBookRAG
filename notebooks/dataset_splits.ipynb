{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "molecular-strand",
   "metadata": {},
   "source": [
    "### Dataset splits\n",
    "\n",
    "Form dataset splits using the reference graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "inappropriate-money",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint as pp\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "boxed-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ds = json.load(open('/path/to/dataset.json', 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-cover",
   "metadata": {},
   "source": [
    "### Form the reference graph\n",
    "\n",
    "$G=(V,E)$\n",
    "- $v\\in V$: theorem, definition, other page\n",
    "- $(u, v)\\in E$: $u$ occurs in the statement or a proof of $v$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "superb-tribe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877 1-cycles\n"
     ]
    }
   ],
   "source": [
    "refs = raw_ds['dataset']['theorems'] + raw_ds['dataset']['definitions'] + raw_ds['dataset']['other']\n",
    "\n",
    "graph = defaultdict(list)\n",
    "\n",
    "id2ref = {}\n",
    "ref2id = {}\n",
    "for r in refs:\n",
    "    ref2id[r['title']] = r['id']\n",
    "    id2ref[r['id']] = r\n",
    "    \n",
    "title2proof = {}\n",
    "for p in raw_ds['dataset']['proofs']:\n",
    "    title2proof[p['title']] = p\n",
    "    \n",
    "pairs = []\n",
    "cycles = []\n",
    "for r1 in refs:\n",
    "    \n",
    "    # Make an edge for each reference in the _statement_\n",
    "    for r2 in r1['refs']:\n",
    "        \n",
    "        r1id = r1['id']\n",
    "        r2id = ref2id[r2]\n",
    "        \n",
    "        if r1id != r2id:\n",
    "            graph[r2id].append(r1id)\n",
    "            \n",
    "            pairs.append((r2id, r1id))\n",
    "            \n",
    "            if r2id in graph[r1id]:\n",
    "                cycles.append(tuple(sorted((r2id, r1id))))\n",
    "                \n",
    "    # Make an edge for each reference in the _proof_ (when available)\n",
    "    if r1['type'] == 'theorem' and r1['has_proof']:\n",
    "        for title in r1['proof_titles']:\n",
    "            proof = title2proof[title]\n",
    "            \n",
    "            for r2 in proof['refs']:                \n",
    "                r1id = r1['id']\n",
    "                r2id = ref2id[r2]\n",
    "                if r1id != r2id:\n",
    "                    graph[r2id].append(r1id)\n",
    "                    \n",
    "                    pairs.append((r2id, r1id))\n",
    "\n",
    "                    if r2id in graph[r1id]:\n",
    "                        cycles.append(tuple(sorted((r2id, r1id))))\n",
    "\n",
    "cycles = set(cycles)\n",
    "print(\"%d 1-cycles\" % (len(cycles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "champion-fence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30681 nodes\n",
      "12396 leaf\n",
      "18285 non-leaf\n",
      "\n",
      "1392 heads\n"
     ]
    }
   ],
   "source": [
    "import networkx\n",
    "\n",
    "G = networkx.DiGraph(graph)\n",
    "leafs = [node for node in G.nodes() if G.in_degree(node) != 0 and G.out_degree(node)==0]\n",
    "nonleafs = [node for node in G.nodes() if G.in_degree(node) == 0 or G.out_degree(node) != 0]\n",
    "heads = [node for node in G.nodes() if G.in_degree(node) == 0 and G.out_degree(node) > 0]\n",
    "\n",
    "print(\"%d nodes\\n%d leaf\\n%d non-leaf\\n\\n%d heads\" % (\n",
    "    len(G.nodes()),\n",
    "    len(leafs),\n",
    "    len(nonleafs),\n",
    "    len(heads)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-reception",
   "metadata": {},
   "source": [
    "#### BFS layers\n",
    "\n",
    "Form BFS layers, count the number of nodes, example-worthy theorems (has proof(s) + contents), and 1-cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "furnished-genius",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total nodes 30681\n",
      "\n",
      "layer\tnodes\tthms\tleaf_thms\n",
      "0\t1392\t0\t0\n",
      "1\t10850\t5777\t2376\n",
      "2\t11713\t5644\t2581\n",
      "3\t5239\t1898\t788\n",
      "4\t1322\t252\t107\n",
      "5\t141\t25\t12\n",
      "6\t14\t1\t0\n"
     ]
    }
   ],
   "source": [
    "print(\"total nodes %d\\n\" % len(G.nodes()))\n",
    "\n",
    "incycle = set()\n",
    "for a, b in cycles:\n",
    "    incycle.add(a)\n",
    "    incycle.add(b)\n",
    "\n",
    "# theorems that correspond to examples (e.g. has a proof, contents)\n",
    "tid2eid = {}\n",
    "for item in raw_ds['dataset']['retrieval_examples']:\n",
    "    tid2eid[item['theorem_id']] = item['example_id']\n",
    "    \n",
    "layers = defaultdict(set)\n",
    "nleafs = []\n",
    "\n",
    "seen = set()\n",
    "for node in heads:\n",
    "    layers[0].add(node)\n",
    "    seen.add(node)\n",
    "    \n",
    "layer = 0\n",
    "print('layer', 'nodes', 'thms', 'leaf_thms', sep='\\t')\n",
    "\n",
    "while len(layers[layer]) > 0:\n",
    "    thms = [x for x in layers[layer] if x in tid2eid]\n",
    "    leaf_thms = [x for x in layers[layer] if x in tid2eid\n",
    "        and x in leafs\n",
    "        and (x not in incycle)\n",
    "    ]\n",
    "    nleafs.append(len(leaf_thms))\n",
    "    \n",
    "    print(layer, len(layers[layer]), len(thms), len(leaf_thms), sep='\\t')\n",
    "    for node in layers[layer]:\n",
    "        for child in G.successors(node):\n",
    "            if child not in seen:\n",
    "                layers[layer+1].add(child)\n",
    "                seen.add(child)\n",
    "    layer += 1\n",
    "\n",
    "nleafs.append(0)\n",
    "    \n",
    "nleafs = np.array(nleafs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-happiness",
   "metadata": {},
   "source": [
    "#### Define the train, valid, test splits\n",
    "\n",
    "We define valid $\\cup$ test as leaves, selected at each layer proportional to the number of leaves at the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "banned-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "budget = 2200\n",
    "leaf_frac = nleafs/nleafs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bottom-oxford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_refs 28473\n",
      "eval_thms 2198\n",
      "eval_refs 2198\n",
      "train_thms 11399\n"
     ]
    }
   ],
   "source": [
    "rand = np.random.RandomState(42)\n",
    "\n",
    "splits = defaultdict(set)\n",
    "\n",
    "for layer in range(len(layers)):\n",
    "        \n",
    "    # get number of eval leaves for this layer\n",
    "    nleaf = int(budget*leaf_frac[layer])\n",
    "    \n",
    "    # randomly sample `nleaf` leaf theorems\n",
    "    leaf_thms = [x for x in layers[layer] if x in tid2eid\n",
    "        and x in leafs\n",
    "        and (x not in incycle)\n",
    "    ]\n",
    "    perm = rand.permutation(len(leaf_thms))\n",
    "    eval_thms = [leaf_thms[i] for i in perm[:nleaf]]\n",
    "    \n",
    "    # collect as evaluation theorems and references\n",
    "    for x in eval_thms:\n",
    "        splits['eval_thms'].add(x)\n",
    "        splits['eval_refs'].add(x)\n",
    "    \n",
    "    # collect all other items as training data\n",
    "    eval_thms_set = set(eval_thms)\n",
    "    for x in layers[layer]:\n",
    "        if x not in eval_thms_set:\n",
    "            splits['train_refs'].add(x)\n",
    "            if x in tid2eid:\n",
    "                splits['train_thms'].add(x)\n",
    "                \n",
    "for k in splits:\n",
    "    splits[k] = list(splits[k])\n",
    "    print(k, len(splits[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-range",
   "metadata": {},
   "source": [
    "#### Verify that evaluation theorems are not referred in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "boolean-beauty",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2198/2198 [00:42<00:00, 51.90it/s]\n"
     ]
    }
   ],
   "source": [
    "for x in tqdm(splits['eval_thms'], total=len(splits['eval_thms'])):\n",
    "    for y in splits['train_refs']:\n",
    "        if G.has_predecessor(y, x):\n",
    "            print(id2ref[x]['title'], id2ref[y]['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-lighter",
   "metadata": {},
   "source": [
    "#### Randomly split evaluation into validation and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "trying-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = np.random.RandomState(42)\n",
    "perm = rand.permutation(len(splits['eval_thms']))\n",
    "\n",
    "idx = len(splits['eval_thms'])//2\n",
    "val_idxs = perm[:idx]\n",
    "\n",
    "val_thms = [splits['eval_thms'][i] for i in perm[:idx]]\n",
    "tst_thms = [splits['eval_thms'][i] for i in perm[idx:]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-causing",
   "metadata": {},
   "source": [
    "#### Convert theorem ids to example ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "religious-devon",
   "metadata": {},
   "outputs": [],
   "source": [
    "tid2eid = {}\n",
    "for item in raw_ds['dataset']['retrieval_examples']:\n",
    "    tid2eid[item['theorem_id']] = item['example_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "centered-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_splits = {\n",
    "    'train': {},\n",
    "    'valid': {},\n",
    "    'test': {}\n",
    "}\n",
    "\n",
    "final_splits['train']['ref_ids'] = splits['train_refs']\n",
    "final_splits['train']['example_ids'] = [tid2eid[t] for t in splits['train_thms']]\n",
    "\n",
    "final_splits['valid']['ref_ids'] = splits['train_refs'] + splits['eval_refs']\n",
    "final_splits['valid']['example_ids'] = [tid2eid[t] for t in val_thms]\n",
    "\n",
    "final_splits['test']['ref_ids'] = splits['train_refs'] + splits['eval_refs']\n",
    "final_splits['test']['example_ids'] = [tid2eid[t] for t in tst_thms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cooperative-dietary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "ref_ids 28473\n",
      "example_ids 11399\n",
      "\n",
      "valid\n",
      "ref_ids 30671\n",
      "example_ids 1099\n",
      "\n",
      "test\n",
      "ref_ids 30671\n",
      "example_ids 1099\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in final_splits:\n",
    "    print(k)\n",
    "    for k2 in final_splits[k]:\n",
    "        print(k2, len(final_splits[k][k2]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "blessed-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ds['splits'] = final_splits\n",
    "\n",
    "import json\n",
    "with open('/path/to/dataset.json', 'w') as f:\n",
    "    json.dump(raw_ds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-estate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-abortion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-beast",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
