{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "proper-sellers",
   "metadata": {},
   "source": [
    "## Output space converter\n",
    "\n",
    "This is used for the `both` (proofwiki+stacks) joint/autoregressive model.\n",
    "\n",
    "The model's output space is over proofwiki and stacks reference ids.\n",
    "\n",
    "When evaluating on an individual dataset, we need to map the model's token id in the combined space to correspond to the reference id from the individual dataset.\n",
    "\n",
    "The end result is a `tok2tok.pkl` file that is used during evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint as pp\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = './data'\n",
    "outdir = './other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "both = json.load(open(os.path.join(base, 'naturalproofs_both.json')))['dataset']\n",
    "pw = json.load(open(os.path.join(base, 'naturalproofs_proofwiki.json')))['dataset']\n",
    "stacks = json.load(open(os.path.join(base, 'naturalproofs_stacks.json')))['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "bothrid2pwrid = {}\n",
    "\n",
    "rid2label = defaultdict(lambda: defaultdict(str))\n",
    "label2rid = defaultdict(lambda: defaultdict(str))\n",
    "\n",
    "for r in both['theorems'] + both['definitions'] + both['others']:\n",
    "    rid2label['both'][r['id']] = r['label']\n",
    "    label2rid['both'][r['label']] = r['id']\n",
    "    \n",
    "for r in pw['theorems'] + pw['definitions'] + pw['others']:\n",
    "    rid2label['pw'][r['id']] = r['label']\n",
    "    label2rid['pw'][r['label']] = r['id']\n",
    "    \n",
    "for r in stacks['theorems'] + stacks['definitions'] + stacks['others']:\n",
    "    rid2label['stacks'][r['id']] = r['label']\n",
    "    label2rid['stacks'][r['label']] = r['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "rid2rid = {\n",
    "    'both2pw': {},\n",
    "    'both2stacks': {},\n",
    "}\n",
    "\n",
    "for rid in rid2label['pw']:\n",
    "    label = rid2label['pw'][rid]\n",
    "    rid_both = label2rid['both'][label]\n",
    "    rid2rid['both2pw'][rid_both] = rid\n",
    "    \n",
    "for rid in rid2label['stacks']:\n",
    "    label = rid2label['stacks'][rid]\n",
    "    rid_both = label2rid['both'][label]\n",
    "    rid2rid['both2stacks'][rid_both] = rid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoreg_both = pickle.load(\n",
    "    open(os.path.join(base, 'sequence_both__bert-base-cased.pkl'), 'rb')\n",
    ")\n",
    "\n",
    "autoreg_pw = pickle.load(\n",
    "    open(os.path.join(base, 'sequence_proofwiki__bert-base-cased.pkl'), 'rb')\n",
    ")\n",
    "\n",
    "autoreg_stacks = pickle.load(\n",
    "    open(os.path.join(base, 'sequence_stacks__bert-base-cased.pkl'), 'rb')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok2tok = {\n",
    "    'both2pw': {},\n",
    "    'both2stacks': {},\n",
    "}\n",
    "\n",
    "both_tok2rid = {}\n",
    "pw_tok2rid = {}\n",
    "stacks_tok2rid = {}\n",
    "\n",
    "for rid, tok in autoreg_both['rid2tok'].items():\n",
    "    both_tok2rid[tok] = rid\n",
    "    \n",
    "\n",
    "for both_tok, both_rid in both_tok2rid.items():\n",
    "    if both_rid not in {'<pad>', '<bos>', '<eos>'}:\n",
    "        if both_rid in rid2rid['both2pw']:\n",
    "            pw_rid = rid2rid['both2pw'][both_rid]\n",
    "            pw_tok = autoreg_pw['rid2tok'][pw_rid]\n",
    "            tok2tok['both2pw'][both_tok] = pw_tok\n",
    "    \n",
    "        if both_rid in rid2rid['both2stacks']:\n",
    "            stacks_rid = rid2rid['both2stacks'][both_rid]\n",
    "            stacks_tok = autoreg_stacks['rid2tok'][stacks_rid]\n",
    "            tok2tok['both2stacks'][both_tok] = stacks_tok\n",
    "                \n",
    "    else:\n",
    "        tok2tok['both2pw'][both_tok] = autoreg_pw['rid2tok'][both_rid]\n",
    "        tok2tok['both2stacks'][both_tok] = autoreg_stacks['rid2tok'][both_rid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rid2rid, open(os.path.join(outdir, 'rid2rid.pkl'), 'wb'))\n",
    "pickle.dump(tok2tok, open(os.path.join(outdir, 'tok2tok.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-password",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
